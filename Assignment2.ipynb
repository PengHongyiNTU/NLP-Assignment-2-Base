{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CE7455 Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: PENG HONGYI <br>\n",
    "Matric No: G2105029E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quetion One (i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Named Entity Recognition__ (NER) as an important task in NLP, attemps to classify predefined entities in a sentence. In our assignment, we use _eng.train_ for training, _eng.testa_ for validation and _eng.testb_ for testing.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sentence in the dataset is presented below, where the first columns is the input word and the last column is the output tag. The dataset contains four different types of predefined entities: PERSON, LOCATION, ORGANIZATION, and MISC. As shown in the fourth column, the fourth column contains the groudtruth entity name and the BIO tag, seperated by '-'.\n",
    "\n",
    "| Word    |     |      | Tag    |\n",
    "|---------|-----|------|--------|\n",
    "| EU      | NNP | I-NP | I-ORG  |\n",
    "| rejects | VBZ | I-VP | O      |\n",
    "| German  | JJ  | I-NP | I-MISC |\n",
    "| call    | NN  | I-NP | O      |\n",
    "| to      | TO  | I-VP | O      |\n",
    "| boycott | VB  | I-VP | O      |\n",
    "| British | JJ  | I-NP | I-MISC |\n",
    "| lamb    | NN  | I-NP | O      |\n",
    "| .       | .   | O    | O      |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question one (ii)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 preprocessing steps in the code provided:\n",
    "* Replacing all the digit with 0.\n",
    "* Convert BIO tagging to BIOES tagging.\n",
    "* Generate words mapping.\n",
    "* Generate tag mapping.\n",
    "* Generate chracter mapping.\n",
    "Mappings here are dictionaries that assign an integer id to every unique word, character and tag. After the proprocessing step, we found: \n",
    "\n",
    "> Found 17493 unique words (203621 in total) \n",
    "Found 75 unique characters \n",
    "Found 19 unique named entity tags\n",
    "\n",
    "The preprocessed dataset is stored in _data/mapping.pkl_. To save time, we will directly processed data throughout this assignment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['word_to_id', 'tag_to_id', 'char_to_id', 'parameters', 'word_embeds']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "import pickle\n",
    "with open('data/mapping.pkl', 'rb') as f:\n",
    "    mapping = pickle.load(f)\n",
    "list(mapping.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = mapping['word_to_id']\n",
    "tag_to_id = mapping['tag_to_id']\n",
    "char_to_id = mapping['char_to_id']\n",
    "# We use our own parameters\n",
    "# parameters = mapping['parameters']\n",
    "word_embeds = mapping['word_embeds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import torch\n",
    "parameters = OrderedDict()\n",
    "parameters['train'] = \"./data/eng.train\" #Path to train file\n",
    "parameters['dev'] = \"./data/eng.testa\" #Path to test file\n",
    "parameters['test'] = \"./data/eng.testb\" #Path to dev file\n",
    "parameters['tag_scheme'] = \"BIOES\" #BIO or BIOES\n",
    "parameters['lower'] = True # Boolean variable to control lowercasing of words\n",
    "parameters['zeros'] =  True # Boolean variable to control replacement of  all digits by 0 \n",
    "parameters['char_dim'] = 30 #Char embedding dimension\n",
    "parameters['word_dim'] = 100 #Token embedding dimension\n",
    "parameters['word_lstm_dim'] = 200 #Token LSTM hidden layer size\n",
    "parameters['word_bidirect'] = True #Use a bidirectional LSTM for words\n",
    "parameters['embedding_path'] = \"./data/glove.6B.100d.txt\" #Location of pretrained embeddings\n",
    "parameters['all_emb'] = 1 #Load all embeddings\n",
    "parameters['crf'] =1 #Use CRF (0 to disable)\n",
    "parameters['dropout'] = 0.5 #Droupout on the input (0 = no dropout)\n",
    "parameters['epoch'] =  50 #Number of epochs to run\"\n",
    "parameters['weights'] = \"\" #path to Pretrained for from a previous run\n",
    "parameters['name'] = \"self-trained-model\" # Model name\n",
    "parameters['gradient_clip']=5.0\n",
    "parameters['char_mode']=\"CNN\"\n",
    "models_path = \"./models/\" #path to saved models\n",
    "parameters['use_gpu'] = torch.cuda.is_available() #GPU Check\n",
    "use_gpu = parameters['use_gpu']\n",
    "parameters['reload'] = \"./models/pre-trained-model\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import load_sentences\n",
    "from TagConversion import update_tag_scheme\n",
    "train_sentences = load_sentences(parameters['train'], parameters['zeros'])\n",
    "test_sentences = load_sentences(parameters['test'], parameters['zeros'])\n",
    "val_sentences = load_sentences(parameters['dev'], parameters['zeros'])\n",
    "update_tag_scheme(train_sentences, parameters['tag_scheme'])\n",
    "update_tag_scheme(val_sentences, parameters['tag_scheme'])\n",
    "update_tag_scheme(test_sentences, parameters['tag_scheme'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14041 / 3250 / 3453 sentences in train / val / test.\n"
     ]
    }
   ],
   "source": [
    "from Utils import prepare_dataset\n",
    "\n",
    "train_data = prepare_dataset(\n",
    "    train_sentences, word_to_id, char_to_id, tag_to_id, parameters['lower']\n",
    ")\n",
    "val_data = prepare_dataset(\n",
    "    val_sentences, word_to_id, char_to_id, tag_to_id, parameters['lower']\n",
    ")\n",
    "test_data = prepare_dataset(\n",
    "    test_sentences, word_to_id, char_to_id, tag_to_id, parameters['lower']\n",
    ")\n",
    "print(\"{} / {} / {} sentences in train / val / test.\".format(len(train_data), len(val_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lianran/phy/NLP-Assignment-2-Base/Init.py:8: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  nn.init.uniform(input_embedding, -bias, bias)\n",
      "/home/lianran/phy/NLP-Assignment-2-Base/Init.py:44: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  nn.init.uniform(weight, -sampling_range, sampling_range)\n",
      "/home/lianran/phy/NLP-Assignment-2-Base/Init.py:49: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  nn.init.uniform(weight, -sampling_range, sampling_range)\n",
      "/home/lianran/phy/NLP-Assignment-2-Base/Init.py:57: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  nn.init.uniform(weight, -sampling_range, sampling_range)\n",
      "/home/lianran/phy/NLP-Assignment-2-Base/Init.py:60: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  nn.init.uniform(weight, -sampling_range, sampling_range)\n",
      "/home/lianran/phy/NLP-Assignment-2-Base/Init.py:16: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  nn.init.uniform(input_linear.weight, -bias, bias)\n"
     ]
    }
   ],
   "source": [
    "from BaseModel import BiLSTM_CRF\n",
    "model = BiLSTM_CRF(vocab_size=len(word_to_id),\n",
    "                   tag_to_ix=tag_to_id,\n",
    "                   embedding_dim=parameters['word_dim'],\n",
    "                   hidden_dim=parameters['word_lstm_dim'],\n",
    "                   use_gpu=use_gpu,\n",
    "                   char_to_ix=char_to_id,\n",
    "                   pre_word_embeds=word_embeds,\n",
    "                   use_crf=parameters['crf'],\n",
    "                   char_mode=parameters['char_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base model contain 2284255 parameters\n"
     ]
    }
   ],
   "source": [
    "num_parameters = count_parameters(model)\n",
    "print(f'The base model contain {num_parameters} parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model reloaded : ./models/pre-trained-model\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(parameters['reload']))\n",
    "print(\"model reloaded :\", parameters['reload'])\n",
    "if use_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "from Helper import get_chunks\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def evaluate(model, datas):\n",
    "    prediction = []\n",
    "    correct_preds, total_correct, total_preds = 0., 0., 0.\n",
    "    for data in tqdm(datas, total=len(datas)):\n",
    "        ground_truth_id = data['tags']\n",
    "        words = data['str_words']\n",
    "        chars2 = data['chars']\n",
    "        if parameters['char_mode'] == 'LSTM':\n",
    "            chars2_sorted = sorted(chars2, key=lambda p: len(p), reverse=True)\n",
    "            d = {}\n",
    "            for i, ci in enumerate(chars2):\n",
    "                for j, cj in enumerate(chars2_sorted):\n",
    "                    if ci == cj and not j in d and not i in d.values():\n",
    "                        d[j] = i\n",
    "                        continue\n",
    "            chars2_length = [len(c) for c in chars2_sorted]\n",
    "            char_maxl = max(chars2_length)\n",
    "            chars2_mask = np.zeros(\n",
    "                (len(chars2_sorted), char_maxl), dtype='int')\n",
    "            for i, c in enumerate(chars2_sorted):\n",
    "                chars2_mask[i, :chars2_length[i]] = c\n",
    "            chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
    "\n",
    "        if parameters['char_mode'] == 'CNN':\n",
    "            d = {}\n",
    "            chars2_length = [len(c) for c in chars2]\n",
    "            char_maxl = max(chars2_length)\n",
    "            chars2_mask = np.zeros(\n",
    "                (len(chars2_length), char_maxl), dtype='int')\n",
    "            for i, c in enumerate(chars2):\n",
    "                chars2_mask[i, :chars2_length[i]] = c\n",
    "            chars2_mask = Variable(torch.LongTensor(chars2_mask))\n",
    "\n",
    "        dwords = Variable(torch.LongTensor(data['words']))\n",
    "        if use_gpu:\n",
    "            val, out = model(\n",
    "                dwords.cuda(), chars2_mask.cuda(), chars2_length, d)\n",
    "        else:\n",
    "            val, out = model(dwords, chars2_mask, chars2_length, d)\n",
    "        predicted_id = out\n",
    "        lab_chunks = set(get_chunks(ground_truth_id, tag_to_id))\n",
    "        lab_pred_chunks = set(get_chunks(predicted_id,\n",
    "                                         tag_to_id))\n",
    "\n",
    "        correct_preds += len(lab_chunks & lab_pred_chunks)\n",
    "        total_preds += len(lab_pred_chunks)\n",
    "        total_correct += len(lab_chunks)\n",
    "\n",
    "    p = correct_preds / total_preds if correct_preds > 0 else 0\n",
    "    r = correct_preds / total_correct if correct_preds > 0 else 0\n",
    "    F = 2 * p * r / (p + r) if correct_preds > 0 else 0\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[31, 48],\n",
       " [6, 0, 52, 0, 12, 2, 7],\n",
       " [42, 0, 6, 14, 1, 3],\n",
       " [12, 1, 9, 9],\n",
       " [2, 5],\n",
       " [21, 5, 19, 12, 5, 2, 2],\n",
       " [36, 6, 4, 2, 4, 7, 11],\n",
       " [9, 1, 14, 21],\n",
       " [18]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['chars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/3453 [00:00<02:34, 22.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char Embeds torch.Size([12, 1, 8, 25])\n",
      "Char Embeds after CNN  torch.Size([12, 25, 10, 1])\n",
      "Char Embeds after Maxpool torch.Size([12, 25])\n",
      "Word Embed torch.Size([12, 100])\n",
      "lstm-out torch.Size([12, 1, 400])\n",
      "Char Embeds torch.Size([2, 1, 5, 25])\n",
      "Char Embeds after CNN  torch.Size([2, 25, 7, 1])\n",
      "Char Embeds after Maxpool torch.Size([2, 25])\n",
      "Word Embed torch.Size([2, 100])\n",
      "lstm-out torch.Size([2, 1, 400])\n",
      "Char Embeds torch.Size([6, 1, 10, 25])\n",
      "Char Embeds after CNN  torch.Size([6, 25, 12, 1])\n",
      "Char Embeds after Maxpool torch.Size([6, 25])\n",
      "Word Embed torch.Size([6, 100])\n",
      "lstm-out torch.Size([6, 1, 400])\n",
      "Char Embeds torch.Size([25, 1, 12, 25])\n",
      "Char Embeds after CNN  torch.Size([25, 25, 14, 1])\n",
      "Char Embeds after Maxpool torch.Size([25, 25])\n",
      "Word Embed torch.Size([25, 100])\n",
      "lstm-out torch.Size([25, 1, 400])\n",
      "Char Embeds torch.Size([25, 1, 10, 25])\n",
      "Char Embeds after CNN  torch.Size([25, 25, 12, 1])\n",
      "Char Embeds after Maxpool torch.Size([25, 25])\n",
      "Word Embed torch.Size([25, 100])\n",
      "lstm-out torch.Size([25, 1, 400])\n",
      "Char Embeds torch.Size([42, 1, 11, 25])\n",
      "Char Embeds after CNN  torch.Size([42, 25, 13, 1])\n",
      "Char Embeds after Maxpool torch.Size([42, 25])\n",
      "Word Embed torch.Size([42, 100])\n",
      "lstm-out torch.Size([42, 1, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 6/3453 [00:00<05:18, 10.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char Embeds torch.Size([23, 1, 11, 25])\n",
      "Char Embeds after CNN  torch.Size([23, 25, 13, 1])\n",
      "Char Embeds after Maxpool torch.Size([23, 25])\n",
      "Word Embed torch.Size([23, 100])\n",
      "lstm-out torch.Size([23, 1, 400])\n",
      "Char Embeds torch.Size([17, 1, 8, 25])\n",
      "Char Embeds after CNN  torch.Size([17, 25, 10, 1])\n",
      "Char Embeds after Maxpool torch.Size([17, 25])\n",
      "Word Embed torch.Size([17, 100])\n",
      "lstm-out torch.Size([17, 1, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/3453 [00:00<05:37, 10.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char Embeds torch.Size([18, 1, 10, 25])\n",
      "Char Embeds after CNN  torch.Size([18, 25, 12, 1])\n",
      "Char Embeds after Maxpool torch.Size([18, 25])\n",
      "Word Embed torch.Size([18, 100])\n",
      "lstm-out torch.Size([18, 1, 400])\n",
      "Char Embeds torch.Size([28, 1, 9, 25])\n",
      "Char Embeds after CNN  torch.Size([28, 25, 11, 1])\n",
      "Char Embeds after Maxpool torch.Size([28, 25])\n",
      "Word Embed torch.Size([28, 100])\n",
      "lstm-out torch.Size([28, 1, 400])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 10/3453 [00:01<05:53,  9.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Char Embeds torch.Size([38, 1, 10, 25])\n",
      "Char Embeds after CNN  torch.Size([38, 25, 12, 1])\n",
      "Char Embeds after Maxpool torch.Size([38, 25])\n",
      "Word Embed torch.Size([38, 100])\n",
      "lstm-out torch.Size([38, 1, 400])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37745/3600084593.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Original Model Test F1-Score: {f_score}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_37745/3929238502.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, datas)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mdwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             val, out = model(\n\u001b[0m\u001b[1;32m     43\u001b[0m                 dwords.cuda(), chars2_mask.cuda(), chars2_length, d)\n\u001b[1;32m     44\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/phy-env/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/phy/NLP-Assignment-2-Base/BaseModel.py\u001b[0m in \u001b[0;36mforward_calc\u001b[0;34m(self, sentence, chars, chars2_length, d)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;31m# Find the best path, given the features.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_crf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviterbi_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/phy/NLP-Assignment-2-Base/BaseModel.py\u001b[0m in \u001b[0;36mviterbi_algo\u001b[0;34m(self, feats)\u001b[0m\n\u001b[1;32m    235\u001b[0m             \u001b[0mforward_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfeat\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mnext_tag_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagset_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtagset_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbptrs_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tag_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             \u001b[0mbptrs_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbptrs_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# holds the backpointers for this step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f_score = evaluate(model, test_data)\n",
    "print(f'Original Model Test F1-Score: {f_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3453/3453 [03:46<00:00, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Test F1-Score: 0.8401554170055119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "f_score = evaluate(model, test_data)\n",
    "print(f'Original Model Test F1-Score: {f_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the trained model provided at https://github.com/TheAnig/NER-LSTM-CNN-Pytorch/raw/master/trained-model-cpu and evaluate it performance on the test set. The test f1-score is:\n",
    "> trained model: __0.84__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question one (iii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either an CNN and an LSTM can be used to perform character-level encoding\n",
    "In the provided code, the CNN is declared as \n",
    "```\n",
    "char_cnn = nn.Conv2d(in_channels=1, out_channels=self.out_channels, kernel_size=(3, char_embedding_dim), padding=(2,0))\n",
    "```\n",
    "Whereas, the LSTM is defined as\n",
    "```\n",
    "char_lstm = nn.LSTM(char_embedding_dim, char_lstm_dim, num_layers=1, bidirectional=True)\n",
    "                init_lstm(self.char_lstm)\n",
    "```\n",
    "No matter what characte-level encoder is used, the extracted character-level representation will be contactenated with higher-level word embeddings and be fed into a Bidirectional lstm. However, for different encoder, the input dimension for the higher-level LSTM are different. If CNN is used, the input dimension is word_embedding_dim + out_channeles. If LSTM is used, the input dimension is word_embedding_dim + char_lstm_dim * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question one (iV)\n",
    "As mentioned in the previous section, word embeddings, contactenated with the characte level embedding, are fed into an LSTM.\n",
    "In this section, we will replace the LSTM with CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneCNN_WordEncoderModel(BiLSTM_CRF):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        print(self.lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(125, 200, bidirectional=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lianran/phy/NLP-Assignment-2-Base/Init.py:8: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  nn.init.uniform(input_embedding, -bias, bias)\n",
      "/home/lianran/phy/NLP-Assignment-2-Base/Init.py:44: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  nn.init.uniform(weight, -sampling_range, sampling_range)\n",
      "/home/lianran/phy/NLP-Assignment-2-Base/Init.py:49: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  nn.init.uniform(weight, -sampling_range, sampling_range)\n",
      "/home/lianran/phy/NLP-Assignment-2-Base/Init.py:57: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  nn.init.uniform(weight, -sampling_range, sampling_range)\n",
      "/home/lianran/phy/NLP-Assignment-2-Base/Init.py:60: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  nn.init.uniform(weight, -sampling_range, sampling_range)\n",
      "/home/lianran/phy/NLP-Assignment-2-Base/Init.py:16: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
      "  nn.init.uniform(input_linear.weight, -bias, bias)\n"
     ]
    }
   ],
   "source": [
    "model = OneCNN_WordEncoderModel(vocab_size=len(word_to_id),\n",
    "                   tag_to_ix=tag_to_id,\n",
    "                   embedding_dim=parameters['word_dim'],\n",
    "                   hidden_dim=parameters['word_lstm_dim'],\n",
    "                   use_gpu=use_gpu,\n",
    "                   char_to_ix=char_to_id,\n",
    "                   pre_word_embeds=word_embeds,\n",
    "                   use_crf=parameters['crf'],\n",
    "                   char_mode=parameters['char_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[944, 15473, 198, 590, 8, 3848, 207, 6233, 2]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1, 400])\n",
      "torch.Size([10, 20, 116])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[10]' is invalid for input of size 3800",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37745/403642951.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[10]' is invalid for input of size 3800"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "with torch.no_grad():\n",
    "    x  = torch.randn(10 , 1, 125)\n",
    "    test = nn.Conv1d(in_channels=1, out_channels=20, kernel_size=10)\n",
    "    pool = nn.MaxPool1d(6)\n",
    "    y, _ = model.lstm(x)\n",
    "    test_y = test(x)\n",
    "    print(y.shape)\n",
    "    print(test_y.shape)\n",
    "    test_y = pool(test_y)\n",
    "    test_y.view(10, )\n",
    "    print(test_y.shape)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f715360d3d4ecb41d67c7d5157bdbc88a6ec901ac9ed57d2d8213181432edb4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
